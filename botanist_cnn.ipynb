{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jcM5xstksSBL"},"outputs":[],"source":["!pip install umap-learn\n","!pip install opencv-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQpTs-iVOHZy"},"outputs":[],"source":["import os\n","import random\n","\n","import numpy as np\n","\n","import cv2\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import matplotlib.pyplot as plt\n","\n","import sklearn.model_selection as skms\n","import sklearn.preprocessing as skp\n","import sklearn.utils as sku\n","import sklearn.decomposition as skd\n","import sklearn.metrics as skm\n","\n","from sklearn.manifold import TSNE\n","from sklearn.model_selection import KFold\n","\n","import umap.umap_ as umap"]},{"cell_type":"markdown","metadata":{"id":"FeyOToxdTux3"},"source":["###Important : prepare data  \n","If you use google colab\n","* please set `USE_GOOGLE_COLAB` to true\n","* Please set the `COLAB_WORKING_PATH` variable to the path of the data zip folder.\n","* Please set the `DATA_CROP_PATH` variable to the path of the folder containing the pre-processed neuchatel dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pU1FJAflPcim"},"outputs":[],"source":["# GOOGLE COLAB\n","USE_GOOGLE_COLAB = True # Are you using Google Colab ?\n","COLAB_WORKING_PATH = \"/content/drive/My Drive/Colab/Botanist\" if USE_GOOGLE_COLAB else \".\"\n","\n","# Mount on Google Drive\n","if USE_GOOGLE_COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive/', force_remount=True)\n","\n","# PATHS\n","DATASET_ZIP_PATH = f\"{COLAB_WORKING_PATH}/herbier.zip\" # Path to zipped data\n","DATASET_PATH = \"/content/data/\"  if USE_GOOGLE_COLAB else \"./\"\n","\n","WORKDIR = f\"{DATASET_PATH}herbier\"\n","WORD_DATA_PATH = f\"{WORKDIR}/data_public/words/\"\n","METADATA_PATH = f\"{WORKDIR}/data_public/ascii/words.txt\"\n","DATA_CROP_PATH = f\"{COLAB_WORKING_PATH}/data_crop/\"\n","if USE_GOOGLE_COLAB:\n","  DATA_CROP_PATH = \"/content/drive/My Drive/Colab/Botanist/data_crop/\"\n","\n","INFERENCE_DATASET_PATH = f\"{COLAB_WORKING_PATH}/data_crop/\"\n","\n","# Create our data folder, unzip the data\n","if USE_GOOGLE_COLAB:\n","  if not os.path.exists(WORKDIR):\n","    !mkdir -p $DATASET_PATH\n","    !unzip \"$DATASET_ZIP_PATH\" -d $DATASET_PATH\n","\n","# CNN\n","IMAGE_HEIGHT = 50\n","IMAGE_WIDTH = 75\n","N_CLASSES_PUBLIC_DATASET = 2\n","N_CLASSES_PRIVATE_DATASET = 2\n","\n","# Choose random classes\n","all_dirs = os.listdir(WORD_DATA_PATH)\n","selected_top_dirs = random.sample(all_dirs, N_CLASSES_PUBLIC_DATASET)\n","sub_dirs = {top_dir: os.listdir(os.path.join(WORD_DATA_PATH, top_dir)) for top_dir in selected_top_dirs}\n","random_subdirs = {top_dir: random.choice(sub_dirs[top_dir]) for top_dir in selected_top_dirs}\n","\n","CLASSES = list(random_subdirs.values())\n","print(f\"Selected classes: {CLASSES}\")\n","\n","FLATTEN_LAYER_NAME = 'flattened'\n","\n","DEBUG = True"]},{"cell_type":"markdown","metadata":{"id":"-40IhemDTlK9"},"source":["**Load data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKRq69r4OHZ2"},"outputs":[],"source":["def load_words_data(data_path, metadata_path, selected_writers = []):\n","    if selected_writers == []:\n","        raise ValueError(\"selected_writers must be a non-empty list of writer IDs\")\n","\n","    data = []\n","\n","    with open(metadata_path, 'r') as file:\n","        for line in file:\n","            if not line.startswith(\"#\"):\n","                components = line.strip().split(' ')\n","                word_id = components[0]\n","\n","                parts = word_id.split('-')\n","                writer_id = '-'.join(parts[:2])\n","\n","                if writer_id in selected_writers:\n","                    image_subfolder = parts[0]\n","                    image_filename = f\"{word_id}.png\"\n","                    image_path = os.path.join(data_path, image_subfolder, writer_id, image_filename)\n","\n","                    if os.path.exists(image_path):\n","                        try:\n","                            img = tf.io.read_file(image_path)\n","                            img = tf.image.decode_png(img)\n","                            data.append({\n","                                'image_path': image_path,\n","                                'writer_id': writer_id,\n","                                'image_array': img\n","                            })\n","                        except tf.errors.InvalidArgumentError:\n","                            print(f\"Image not found for word ID: {word_id} at {image_path}\")\n","                    else:\n","                        print(f\"Image not found for word ID: {word_id} at {image_path}\")\n","\n","    return data\n","\n","def load_new_class_data(data_crop_path):\n","    new_class_data = []\n","\n","    class_dirs = os.listdir(data_crop_path)\n","\n","    # Select 2 random folders\n","    selected_dirs = random.sample(class_dirs, 2)\n","\n","    for class_dir in selected_dirs:\n","        class_dir_path = os.path.join(data_crop_path, class_dir)\n","        image_files = os.listdir(class_dir_path)\n","\n","        for image_file in image_files:\n","            image_path = os.path.join(class_dir_path, image_file)\n","\n","            try:\n","                img = tf.io.read_file(image_path)\n","                img = tf.image.decode_png(img)\n","                new_class_data.append({\n","                    'image_path': image_path,\n","                    'writer_id': class_dir,  # Assuming folder name is the class name\n","                    'image_array': img\n","                })\n","            except tf.errors.InvalidArgumentError:\n","                print(f\"Image not found for class {class_dir} at {image_path}\")\n","\n","    return new_class_data\n","\n","words_data = load_words_data(WORD_DATA_PATH, METADATA_PATH, selected_writers=CLASSES)\n","\n","new_classes_data = load_new_class_data(DATA_CROP_PATH)\n","words_data.extend(new_classes_data)\n","\n","images = [entry['image_array'] for entry in words_data]\n","labels = [entry['writer_id'] for entry in words_data]\n","\n","X_train, X_test, y_train, y_test = skms.train_test_split(np.array(images), np.array(labels), test_size=0.2, random_state=42)\n","\n","\n","def plot_images(images, labels, num=5, class_num=N_CLASSES_PUBLIC_DATASET + N_CLASSES_PRIVATE_DATASET):\n","    plt.figure(figsize=(10,10))\n","    for i in range(num):\n","        plt.subplot(class_num,num,i+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(images[i], cmap=plt.cm.binary)\n","        plt.xlabel(labels[i])\n","    plt.show()\n","\n","def plot_random_samples(classes, num=5):\n","  for class_name in classes:\n","      class_indices = np.where(y_train == class_name)[0]\n","      size = min(num, len(class_indices))\n","      random_indices = np.random.choice(class_indices, size=size, replace=False)\n","      random_images = X_train[random_indices]\n","      plot_images(random_images, [class_name] * num)\n","\n","\n","\n","if DEBUG:\n","  print(f\"Loaded {len(words_data)} words.\")\n","  for entry in words_data[:5]:\n","      print(f\"  Writer ID: {entry['writer_id']}; image shape: {entry['image_array'].shape}\")\n","\n","  print(\"number of writers: \", len(set([entry['writer_id'] for entry in words_data])))\n","\n","  plot_random_samples(CLASSES)"]},{"cell_type":"markdown","metadata":{"id":"hL1b3PvLTY5B"},"source":["**Pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeRayEfpOHZ3"},"outputs":[],"source":["def preprocess_data(data):\n","    labels = []\n","    images = []\n","\n","    for entry in data:\n","        # Resize the image while preserving aspect ratio\n","        img = np.array(entry['image_array'])\n","        old_size = img.shape[:2]\n","\n","        ratio = float(IMAGE_HEIGHT)/old_size[0]\n","        new_size = tuple([int(x*ratio) for x in old_size])\n","\n","        img = cv2.resize(img, (new_size[1], new_size[0]))\n","\n","        # Ignore images that are too narrows\n","        if new_size[1] < IMAGE_WIDTH:\n","          continue;\n","\n","        # Crop images that are too wide\n","        if new_size[1] > IMAGE_WIDTH:\n","            start_x = (new_size[1] - IMAGE_WIDTH) // 2\n","            img = img[:, start_x:start_x + IMAGE_WIDTH]\n","            new_size = (new_size[0], IMAGE_WIDTH)\n","\n","        img = img.astype('float32') / 255.0\n","\n","        # Ensure dimensions format is correct: (sample_n, width, height, channels)\n","        img = np.expand_dims(img, axis=-1)\n","        delta_w = IMAGE_WIDTH - new_size[1]\n","        delta_h = IMAGE_HEIGHT - img.shape[0]\n","        delta_w = IMAGE_WIDTH - img.shape[1]\n","        padding = ((0, delta_h), (0, delta_w), (0, 0))\n","        img = np.pad(img, padding, 'constant')\n","\n","        images.append(img)\n","        labels.append(entry['writer_id'])\n","\n","    return np.array(images), np.array(labels)\n","\n","\n","images, labels = preprocess_data(words_data)\n","X_train, X_test, y_train, y_test = skms.train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","if DEBUG:\n","  print(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\")\n","  print(f\"X_test: {X_test.shape}; y_test: {y_test.shape}\")\n","  plot_random_samples(CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbSxp-eGOHZ3"},"outputs":[],"source":["# data augmentation\n","\n","data_generator = keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=False,\n","    fill_mode='nearest'\n",")"]},{"cell_type":"markdown","metadata":{"id":"j5K7LbvLTgbB"},"source":["**Kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPcfiBsVRxG_"},"outputs":[],"source":["# Define number of splits\n","n_splits = 5\n","\n","# Create Kfold instance\n","kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"oLk6ZBvzWKd3"},"source":["**Set function to use kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2--w-RnTsGl"},"outputs":[],"source":["def evaluate_model(n_neighbors, n_neighbors_list, min_dist, min_dist_list, class_labels, ax, features_standardized):\n","      reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=32, metric='euclidean')\n","      embedding = reducer.fit_transform(np.nan_to_num(features_standardized))\n","\n","      sc = ax.scatter(embedding[:, 0], embedding[:, 1],\n","                      c=class_labels, edgecolor='none', alpha=0.5,\n","                      cmap=plt.cm.get_cmap('Accent', N_CLASSES_PUBLIC_DATASET + N_CLASSES_PRIVATE_DATASET))\n","      ax.set_xlabel('UMAP component 1')\n","      ax.set_ylabel('UMAP component 2')\n","      ax.set_title(f'n_neighbors={n_neighbors}, min_dist={min_dist}')\n","\n","      if n_neighbors == n_neighbors_list[-1] and min_dist == min_dist_list[-1]:\n","          plt.colorbar(sc, ax=ax)\n","\n","def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n","  BATCH_SIZE = 5 # fine tuned\n","  EPOCHS = 30\n","\n","  train_generator = data_generator.flow(X_train, y_train, batch_size=BATCH_SIZE)\n","\n","  class_weights = sku.compute_class_weight(\n","      class_weight='balanced',\n","      classes=np.unique(integer_class_labels),\n","      y=integer_class_labels\n","  )\n","  class_weights_dict = {i : weight for i, weight in enumerate(class_weights)}\n","\n","  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","  history = model.fit(\n","      train_generator,\n","      epochs=EPOCHS,\n","      steps_per_epoch=len(X_train) // BATCH_SIZE,  # Number of batches per epoch\n","      validation_data=(X_test, y_test),\n","      class_weight=class_weights_dict,\n","      callbacks=[early_stopping]\n","  )\n","\n","  ############\n","\n","  feature_layer = model.get_layer(FLATTEN_LAYER_NAME).output\n","\n","  # Create a feature extractor model\n","  feature_extractor_model = keras.models.Model(inputs=model.input, outputs=feature_layer)\n","\n","  # Now you can use this model to extract features\n","  features = feature_extractor_model.predict(X_train)\n","\n","  ############\n","\n","  # features = model.predict(X_train)\n","\n","  if DEBUG:\n","      print(f\"features shape: {features.shape}\")\n","\n","  # Standardize the features\n","  scaler = skp.StandardScaler()\n","  features_standardized = scaler.fit_transform(features)\n","\n","  # Now, use the standardized features with UMAP\n","  n_neighbors_list = [10, 20, 30]\n","  min_dist_list = [0.0, 0.1, 0.2]\n","\n","  fig, axes = plt.subplots(len(n_neighbors_list), len(min_dist_list), figsize=(15, 12))\n","\n","  axes = axes.flatten()\n","\n","  for idx, (n_neighbors, min_dist) in enumerate([(x, y) for x in n_neighbors_list for y in min_dist_list]):\n","      evaluate_model(n_neighbors, n_neighbors_list, min_dist, min_dist_list, integer_class_labels, axes[idx], features_standardized)\n","\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eygzGbC1ud1n"},"source":["**Define model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H38Z_UwRudUk"},"outputs":[],"source":["# Define modele\n","input_layer = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n","\n","# Define L1 and L2 regularization\n","l1_l2 = keras.regularizers.l1_l2(l1=0, l2=1e-4)\n","\n","# path 1\n","conv1_1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2)(input_layer)\n","pool1_1 = keras.layers.MaxPooling2D((2, 2))(conv1_1)\n","conv1_2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l1_l2)(pool1_1)\n","pool1_2 = keras.layers.MaxPooling2D((2, 2))(conv1_2)\n","\n","# path 2\n","conv2_1 = keras.layers.Conv2D(32, (5, 5), activation='relu', padding='same', kernel_regularizer=l1_l2)(input_layer)\n","pool2_1 = keras.layers.MaxPooling2D((2, 2))(conv2_1)\n","conv2_2 = keras.layers.Conv2D(64, (5, 5), activation='relu', padding='same', kernel_regularizer=l1_l2)(pool2_1)\n","pool2_2 = keras.layers.MaxPooling2D((2, 2))(conv2_2)\n","\n","# merge paths\n","merged = keras.layers.concatenate([pool1_2, pool2_2])\n","\n","flat = keras.layers.Flatten()(merged)\n","dense1 = keras.layers.Dense(128, activation='relu', kernel_regularizer=l1_l2, name=FLATTEN_LAYER_NAME)(flat)\n","dropout = keras.layers.Dropout(0.2)(dense1)  # Consider experimenting with the dropout rate\n","output_layer = keras.layers.Dense(N_CLASSES_PUBLIC_DATASET + N_CLASSES_PRIVATE_DATASET, activation='softmax')(dropout)\n","\n","model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","if DEBUG:\n","    model.summary()\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"sG-G3wQJWOCn"},"source":["**Use kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNujF2FVR7w7"},"outputs":[],"source":["# Execute kfold\n","for fold, (train_index, test_index) in enumerate(kf.split(images), 1):\n","\n","    # encode labels\n","    label_encoder = skp.LabelEncoder()\n","    integer_encoded_labels = label_encoder.fit_transform(labels)\n","    one_hot_encoded_labels = keras.utils.to_categorical(integer_encoded_labels)\n","\n","    X_train, X_test = images[train_index], images[test_index]\n","    y_train, y_test = one_hot_encoded_labels[train_index], one_hot_encoded_labels[test_index]\n","\n","    print(f\"\\nFold {fold} - Training set: X_train shape = {X_train.shape}, y_train shape = {y_train.shape}\")\n","    print(f\"Fold {fold} - Testing set: X_test shape = {X_test.shape}, y_test shape = {y_test.shape}\")\n","\n","    integer_class_labels = np.argmax(y_train, axis=1)\n","\n","    # Train and test modele\n","    train_and_evaluate(model, X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"NUsBO89nsSBT"},"source":["**Inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFEyRs6TsSBT"},"outputs":[],"source":["from PIL import Image\n","from sklearn.preprocessing import LabelEncoder\n","\n","dataset_path = DATA_CROP_PATH\n","\n","data = []\n","class_dirs = os.listdir(dataset_path)\n","\n","# Select 2 random folders\n","selected_dirs = random.sample(class_dirs, 2)\n","\n","print(\"Selected classes :\", selected_dirs)\n","\n","# Fetch dataset image\n","for class_dir in selected_dirs:\n","    class_dir_path = os.path.join(dataset_path, class_dir)\n","\n","    image_files = os.listdir(class_dir_path)\n","    for image_file in image_files:\n","        image_path = os.path.join(class_dir_path, image_file)\n","\n","        image = Image.open(image_path)\n","        image_array = np.array(image)\n","\n","        entry = {'image_array': image_array, 'writer_id': class_dir}\n","        data.append(entry)\n","\n","\n","# Prepare data\n","images, labels = preprocess_data(data)\n","\n","le = LabelEncoder()\n","labels = le.fit_transform(labels)\n","\n","X = np.array(images)\n","y = np.array(labels)\n","\n","# Prediction\n","predictions = model.predict(X)\n","\n","predicted_class_labels = np.argmax(predictions, axis=1)\n","true_class_labels = y\n","\n","##############################\n","\n","# Feature extraction and UMAP\n","feature_layer = model.get_layer(FLATTEN_LAYER_NAME).output\n","\n","# Create a feature extractor model\n","feature_extractor_model = keras.models.Model(inputs=model.input, outputs=feature_layer)\n","\n","# Now you can use this model to extract features\n","features = feature_extractor_model.predict(X)\n","\n","if DEBUG:\n","    print(f\"features shape: {features.shape}\")\n","\n","# Standardize the features\n","scaler = skp.StandardScaler()\n","features_standardized = scaler.fit_transform(features)\n","\n","# Now, use the standardized features with UMAP\n","n_neighbors_list = [10, 20, 30]\n","min_dist_list = [0.0, 0.1, 0.2]\n","\n","fig, axes = plt.subplots(len(n_neighbors_list), len(min_dist_list), figsize=(15, 12))\n","\n","axes = axes.flatten()\n","\n","for idx, (n_neighbors, min_dist) in enumerate([(x, y) for x in n_neighbors_list for y in min_dist_list]):\n","    evaluate_model(n_neighbors, n_neighbors_list, min_dist, min_dist_list, predicted_class_labels, axes[idx], features_standardized)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"t4Ua6erRsSBU"},"source":["**Model evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeT7CI0nsSBU"},"outputs":[],"source":["# Plot 10 random images and their corresponding labels\n","indices = np.random.choice(range(len(X)), size=10, replace=False)\n","\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n","\n","for i, idx in enumerate(indices):\n","    ax = axes[i//5, i%5]\n","\n","    ax.imshow(X[idx], cmap=plt.cm.binary)\n","\n","    true_label = le.inverse_transform([y[idx]])[0]\n","    predicted_label = le.inverse_transform([predicted_class_labels[idx]])[0]\n","    title_color = 'green' if true_label == predicted_label else 'red'\n","\n","    ax.set_title(f\"True: {true_label}\\nPredicted: {predicted_label}\", color=title_color)\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxKqdaItsSBU"},"outputs":[],"source":["# Confusion matrix\n","confusion_matrix = skm.confusion_matrix(true_class_labels, predicted_class_labels)\n","\n","plt.figure(figsize=(10, 10))\n","plt.imshow(confusion_matrix, cmap=plt.cm.Blues)\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","\n","# Ajouter les labels aux axes x et y\n","class_names = le.classes_  # Récupérer les noms de classe à partir de l'encodeur\n","tick_marks = np.arange(len(class_names))\n","\n","plt.xticks(tick_marks, class_names, rotation=45)\n","plt.yticks(tick_marks, class_names)\n","\n","# Titre de la matrice de confusion\n","plt.title('Confusion matrix')\n","\n","plt.colorbar()\n","\n","for i in range(confusion_matrix.shape[0]):\n","    for j in range(confusion_matrix.shape[1]):\n","        plt.text(j, i, confusion_matrix[i, j], ha='center', va='center', color='red')\n","\n","plt.show()\n","\n","# Precision, recall, F1 score\n","precision = skm.precision_score(true_class_labels, predicted_class_labels, average='weighted')\n","recall = skm.recall_score(true_class_labels, predicted_class_labels, average='weighted')\n","f1_score = skm.f1_score(true_class_labels, predicted_class_labels, average='weighted')\n","\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 score: {f1_score:.4f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}