{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sN1W8-uZz_qX"},"outputs":[],"source":["!pip uninstall umap -y\n","!pip install umap-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdJjewv_uH9l"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import matplotlib.pyplot as plt\n","\n","import sklearn.model_selection as skms\n","import sklearn.preprocessing as skp\n","import sklearn.utils as sku\n","import sklearn.decomposition as skd\n","import sklearn.metrics as skm\n","\n","from sklearn.manifold import TSNE\n","\n","import cv2\n","\n","# Module for k-fold\n","from sklearn.model_selection import KFold\n","\n","import umap.umap_ as umap"]},{"cell_type":"markdown","source":["###Important : prepare data\n","If you use google colab\n","* please set `USE_GOOGLE_COLAB` to true\n","* Please set the `COLAB_WORKING_PATH` variable to the path of the data zip folder.\n","* Please set the `DATA_CROP_PATH` variable to the path of the folder containing the pre-processed neuchatel dataset."],"metadata":{"id":"e8_YaKMR9xOy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAALNQFi0Bcz"},"outputs":[],"source":["# GOOGLE COLAB\n","USE_GOOGLE_COLAB = True # Are you using Google Colab ?\n","COLAB_WORKING_PATH = \"/content/drive/My Drive/Colab/Botanist\" if USE_GOOGLE_COLAB else \".\"\n","\n","# Mount on Google Drive\n","if USE_GOOGLE_COLAB:\n","  from google.colab import drive\n","  drive.mount('/content/drive/', force_remount=True)\n","\n","# PATHS\n","DATASET_ZIP_PATH = f\"{COLAB_WORKING_PATH}/herbier.zip\" # Path to zipped data\n","DATASET_PATH = \"/content/data/\"  if USE_GOOGLE_COLAB else \"./\"\n","\n","\n","WORKDIR = f\"{DATASET_PATH}herbier\"\n","WORD_DATA_PATH = f\"{WORKDIR}/data_public/words/\"\n","METADATA_PATH = f\"{WORKDIR}/data_public/ascii/words.txt\"\n","DATA_CROP_PATH = f\"{COLAB_WORKING_PATH}/data_crop/\"\n","if USE_GOOGLE_COLAB:\n","  DATA_CROP_PATH = \"/content/drive/My Drive/Colab/Botanist/data_crop/\"\n","\n","INFERENCE_DATASET_PATH = f\"{COLAB_WORKING_PATH}/data_crop/\"\n","\n","# Create our data folder, unzip the data\n","if USE_GOOGLE_COLAB:\n","  if not os.path.exists(WORKDIR):\n","    !mkdir -p $DATASET_PATH\n","    !unzip \"$DATASET_ZIP_PATH\" -d $DATASET_PATH\n","\n","# AE\n","IMAGE_HEIGHT = 128\n","IMAGE_WIDTH = 128\n","N_CLASSES = 2\n","\n","# Choose random classes\n","all_dirs = os.listdir(WORD_DATA_PATH)\n","selected_top_dirs = random.sample(all_dirs, N_CLASSES)\n","sub_dirs = {top_dir: os.listdir(os.path.join(WORD_DATA_PATH, top_dir)) for top_dir in selected_top_dirs}\n","random_subdirs = {top_dir: random.choice(sub_dirs[top_dir]) for top_dir in selected_top_dirs}\n","\n","CLASSES = list(random_subdirs.values())\n","print(f\"Selected classes: {CLASSES}\")\n","\n","FLATTEN_LAYER_NAME = 'flattened'\n","\n","DEBUG = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BOKlqrvuH9o"},"outputs":[],"source":["def load_words_data(data_path, metadata_path, selected_writers = []):\n","    if selected_writers == []:\n","        raise ValueError(\"selected_writers must be a non-empty list of writer IDs\")\n","\n","    data = []\n","\n","    with open(metadata_path, 'r') as file:\n","        for line in file:\n","            if not line.startswith(\"#\"):\n","                components = line.strip().split(' ')\n","                word_id = components[0]\n","\n","                parts = word_id.split('-')\n","                writer_id = '-'.join(parts[:2])\n","\n","                if writer_id in selected_writers:\n","                    image_subfolder = parts[0]\n","                    image_filename = f\"{word_id}.png\"\n","                    image_path = os.path.join(data_path, image_subfolder, writer_id, image_filename)\n","\n","                    if os.path.exists(image_path):\n","                        try:\n","                            img = tf.io.read_file(image_path)\n","                            img = tf.image.decode_png(img)\n","                            data.append({\n","                                'image_path': image_path,\n","                                'writer_id': writer_id,\n","                                'image_array': img\n","                            })\n","                        except tf.errors.InvalidArgumentError:\n","                            print(f\"Image not found for word ID: {word_id} at {image_path}\")\n","                    else:\n","                        print(f\"Image not found for word ID: {word_id} at {image_path}\")\n","\n","    return data\n","\n","def load_new_class_data(data_crop_path):\n","    new_class_data = []\n","\n","    class_dirs = os.listdir(data_crop_path)\n","\n","    # Select 2 random folders\n","    selected_dirs = random.sample(class_dirs, 2)\n","\n","    for class_dir in selected_dirs:\n","        class_dir_path = os.path.join(data_crop_path, class_dir)\n","        image_files = os.listdir(class_dir_path)\n","\n","        for image_file in image_files:\n","            image_path = os.path.join(class_dir_path, image_file)\n","\n","            try:\n","                img = tf.io.read_file(image_path)\n","                img = tf.image.decode_png(img)\n","                new_class_data.append({\n","                    'image_path': image_path,\n","                    'writer_id': class_dir,  # Assuming folder name is the class name\n","                    'image_array': img\n","                })\n","            except tf.errors.InvalidArgumentError:\n","                print(f\"Image not found for class {class_dir} at {image_path}\")\n","\n","    return new_class_data\n","\n","words_data = load_words_data(WORD_DATA_PATH, METADATA_PATH, selected_writers=CLASSES)\n","\n","new_classes_data = load_new_class_data(DATA_CROP_PATH)\n","words_data.extend(new_classes_data)\n","\n","N_CLASSES = N_CLASSES + 2\n","\n","images = [entry['image_array'] for entry in words_data]\n","labels = [entry['writer_id'] for entry in words_data]\n","\n","X_train, X_test, y_train, y_test = skms.train_test_split(np.array(images), np.array(labels), test_size=0.2, random_state=42)\n","\n","\n","def plot_images(images, labels, num=5, class_num=N_CLASSES):\n","    plt.figure(figsize=(10,10))\n","    for i in range(num):\n","        plt.subplot(class_num,num,i+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(images[i], cmap=plt.cm.binary)\n","        plt.xlabel(labels[i])\n","    plt.show()\n","\n","def plot_random_samples(classes, num=5):\n","  for class_name in classes:\n","      class_indices = np.where(y_train == class_name)[0]\n","      size = min(num, len(class_indices))\n","      random_indices = np.random.choice(class_indices, size=size, replace=False)\n","      random_images = X_train[random_indices]\n","      plot_images(random_images, [class_name] * num)\n","\n","\n","\n","if DEBUG:\n","  print(f\"Loaded {len(words_data)} words.\")\n","  for entry in words_data[:5]:\n","      print(f\"  Writer ID: {entry['writer_id']}; image shape: {entry['image_array'].shape}\")\n","\n","  print(\"number of writers: \", len(set([entry['writer_id'] for entry in words_data])))\n","\n","  plot_random_samples(CLASSES)"]},{"cell_type":"markdown","metadata":{"id":"E006hD9Nxo67"},"source":["**Pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hulb4sWRuH9p"},"outputs":[],"source":["def preprocess_data(data):\n","    labels = []\n","    images = []\n","\n","    for entry in data:\n","        # Resize the image while preserving aspect ratio\n","        img = np.array(entry['image_array'])\n","        old_size = img.shape[:2]\n","\n","        ratio = float(IMAGE_HEIGHT)/old_size[0]\n","        new_size = tuple([int(x*ratio) for x in old_size])\n","\n","        img = cv2.resize(img, (new_size[1], new_size[0]))\n","\n","        # Ignore images that are too narrows\n","        if new_size[1] < IMAGE_WIDTH:\n","          continue;\n","\n","        # Crop images that are too wide\n","        if new_size[1] > IMAGE_WIDTH:\n","            start_x = (new_size[1] - IMAGE_WIDTH) // 2\n","            img = img[:, start_x:start_x + IMAGE_WIDTH]\n","            new_size = (new_size[0], IMAGE_WIDTH)\n","\n","        img = img.astype('float32') / 255.0\n","\n","        # Ensure dimensions format is correct: (sample_n, width, height, channels)\n","        img = np.expand_dims(img, axis=-1)\n","        delta_w = IMAGE_WIDTH - new_size[1]\n","        delta_h = IMAGE_HEIGHT - img.shape[0]\n","        delta_w = IMAGE_WIDTH - img.shape[1]\n","        padding = ((0, delta_h), (0, delta_w), (0, 0))\n","        img = np.pad(img, padding, 'constant')\n","\n","        images.append(img)\n","        labels.append(entry['writer_id'])\n","\n","    return np.array(images), np.array(labels)\n","\n","\n","images, labels = preprocess_data(words_data)\n","X_train, X_test, y_train, y_test = skms.train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","if DEBUG:\n","  print(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\")\n","  print(f\"X_test: {X_test.shape}; y_test: {y_test.shape}\")\n","  plot_random_samples(CLASSES)"]},{"cell_type":"code","source":["# data augmentation\n","\n","data_generator = keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=False,\n","    fill_mode='nearest'\n",")"],"metadata":{"id":"bZNK4vfRaeVd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1IoYwESBxxbc"},"source":["**Kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvGW_t68xynh"},"outputs":[],"source":["# Define number of splits\n","n_splits = 5\n","\n","# Create Kfold instance\n","kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"WwFl5G6ZyJw0"},"source":["**Set function to use kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYfw5twWyKTN"},"outputs":[],"source":["def evaluate_model(n_neighbors, n_neighbors_list, min_dist, min_dist_list, class_labels, ax, features_standardized):\n","      reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=32, metric='euclidean')\n","      embedding = reducer.fit_transform(np.nan_to_num(features_standardized))\n","\n","      sc = ax.scatter(embedding[:, 0], embedding[:, 1],\n","                      c=class_labels, edgecolor='none', alpha=0.5,\n","                      cmap=plt.cm.get_cmap('Accent', N_CLASSES))\n","      ax.set_xlabel('UMAP component 1')\n","      ax.set_ylabel('UMAP component 2')\n","      ax.set_title(f'n_neighbors={n_neighbors}, min_dist={min_dist}')\n","\n","      if n_neighbors == n_neighbors_list[-1] and min_dist == min_dist_list[-1]:\n","          plt.colorbar(sc, ax=ax)\n","\n","def train_and_evaluate(encoder_model, X_train, y_train, X_test, y_test):\n","  BATCH_SIZE = 8 # fine tuned\n","  EPOCHS = 100\n","\n","  class_weights = sku.compute_class_weight(\n","      class_weight='balanced',\n","      classes=np.unique(integer_class_labels),\n","      y=integer_class_labels\n","  )\n","  class_weights_dict = {i : weight for i, weight in enumerate(class_weights)}\n","\n","  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","  autoencoder.fit(X_train, X_train,  # input and output are the same for an autoencoder\n","                  epochs=EPOCHS,\n","                  batch_size=BATCH_SIZE,\n","                  shuffle=True,\n","                  validation_data=(X_test, X_test))\n","\n","  ############\n","\n","  # Extract features\n","  encoded_features = encoder_model.predict(X_train)\n","\n","  # Standardize the features\n","  scaler = skp.StandardScaler()\n","  encoded_features_standardized = scaler.fit_transform(encoded_features.reshape(len(encoded_features), -1))\n","\n","  ############\n","\n","  # Standardize the features\n","  # Now, use the standardized features with UMAP\n","  n_neighbors_list = [10, 20, 30]\n","  min_dist_list = [0.0, 0.1, 0.2]\n","\n","  fig, axes = plt.subplots(len(n_neighbors_list), len(min_dist_list), figsize=(15, 12))\n","\n","  axes = axes.flatten()\n","\n","  for idx, (n_neighbors, min_dist) in enumerate([(x, y) for x in n_neighbors_list for y in min_dist_list]):\n","      evaluate_model(n_neighbors, n_neighbors_list, min_dist, min_dist_list, integer_class_labels, axes[idx], encoded_features_standardized)\n","\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"e10nexn-zD5T"},"source":["**Define model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLenrqdSzEdq"},"outputs":[],"source":["# Encoder\n","input_img = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1)) # adapt this if using `channels_first` image data format\n","\n","x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n","x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","encoded = keras.layers.MaxPooling2D((2, 2), padding='same', name='encoded_layer')(x)\n","\n","# Decoder\n","x = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n","x = keras.layers.UpSampling2D((2, 2))(x)\n","x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = keras.layers.UpSampling2D((2, 2))(x)\n","x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = keras.layers.UpSampling2D((2, 2))(x) # Additional upsampling layer\n","decoded = keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","\n","# Autoencoder model\n","autoencoder = keras.Model(input_img, decoded)\n","\n","if DEBUG:\n","    autoencoder.summary()\n","\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Create a model to retrieve the encoded features\n","encoder_model = keras.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoded_layer').output)"]},{"cell_type":"markdown","metadata":{"id":"SpFlp0FDzj4Z"},"source":["**Use kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgHsUXjmzka7"},"outputs":[],"source":["# Execute kfold\n","for fold, (train_index, test_index) in enumerate(kf.split(images), 1):\n","\n","    # encode labels\n","    label_encoder = skp.LabelEncoder()\n","    integer_encoded_labels = label_encoder.fit_transform(labels)\n","    one_hot_encoded_labels = keras.utils.to_categorical(integer_encoded_labels)\n","\n","    X_train, X_test = images[train_index], images[test_index]\n","    y_train, y_test = one_hot_encoded_labels[train_index], one_hot_encoded_labels[test_index]\n","\n","    print(f\"\\nFold {fold} - Training set: X_train shape = {X_train.shape}, y_train shape = {y_train.shape}\")\n","    print(f\"Fold {fold} - Testing set: X_test shape = {X_test.shape}, y_test shape = {y_test.shape}\")\n","\n","    integer_class_labels = np.argmax(y_train, axis=1)\n","\n","    # Train and test modele\n","    train_and_evaluate(encoder_model, X_train, y_train, X_test, y_test)"]},{"cell_type":"markdown","source":["**Inference**"],"metadata":{"id":"mx3a8OeCbCYX"}},{"cell_type":"code","source":["from PIL import Image\n","from sklearn.preprocessing import LabelEncoder\n","\n","dataset_path = DATA_CROP_PATH\n","\n","data = []\n","class_dirs = os.listdir(dataset_path)\n","\n","# Select 2 random folders\n","selected_dirs = random.sample(class_dirs, 2)\n","\n","print(\"Selected classes :\", selected_dirs)\n","\n","# Fetch dataset image\n","for class_dir in selected_dirs:\n","    class_dir_path = os.path.join(dataset_path, class_dir)\n","\n","    image_files = os.listdir(class_dir_path)\n","    for image_file in image_files:\n","        image_path = os.path.join(class_dir_path, image_file)\n","\n","        image = Image.open(image_path)\n","        image_array = np.array(image)\n","\n","        entry = {'image_array': image_array, 'writer_id': class_dir}\n","        data.append(entry)\n","\n","\n","# Prepare data\n","images, labels = preprocess_data(data)\n","\n","le = LabelEncoder()\n","labels = le.fit_transform(labels)\n","\n","X = np.array(images)\n","y = np.array(labels)\n","\n","# Prediction\n","predictions = autoencoder.predict(X)\n","\n","predicted_class_labels = np.argmax(predictions, axis=1)\n","true_class_labels = y\n","\n","##############################\n","\n","# Extract features\n","encoded_features = encoder_model.predict(X)\n","\n","# Standardize the features\n","scaler = skp.StandardScaler()\n","encoded_features_standardized = scaler.fit_transform(encoded_features.reshape(len(encoded_features), -1))\n","\n","# Standardize the features\n","# Now, use the standardized features with UMAP\n","n_neighbors_list = [10, 20, 30]\n","min_dist_list = [0.0, 0.1, 0.2]\n","\n","fig, axes = plt.subplots(len(n_neighbors_list), len(min_dist_list), figsize=(15, 12))\n","\n","axes = axes.flatten()\n","\n","for idx, (n_neighbors, min_dist) in enumerate([(x, y) for x in n_neighbors_list for y in min_dist_list]):\n","    evaluate_model(n_neighbors, n_neighbors_list, min_dist, min_dist_list, true_class_labels, axes[idx], encoded_features_standardized)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"0-Qq3w1ibETv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model evaluation**"],"metadata":{"id":"syrIRKrcbG0Y"}},{"cell_type":"code","source":["# Plot 10 random images and their corresponding labels\n","indices = np.random.choice(range(len(X)), size=10, replace=False)\n","\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n","\n","for i, idx in enumerate(indices):\n","    ax = axes[i//5, i%5]\n","\n","    ax.imshow(X[idx], cmap=plt.cm.binary)\n","\n","    true_label = le.inverse_transform([y[idx]])[0]\n","    predicted_label = le.inverse_transform([true_class_labels[idx]])[0]\n","    title_color = 'green' if true_label == predicted_label else 'red'\n","\n","    ax.set_title(f\"True: {true_label}\\nPredicted: {predicted_label}\", color=title_color)\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"G9qVyBaJbMbs"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}