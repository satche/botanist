{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sN1W8-uZz_qX"},"outputs":[],"source":["!pip uninstall umap -y\n","!pip install umap-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdJjewv_uH9l"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import matplotlib.pyplot as plt\n","\n","import sklearn.model_selection as skms\n","import sklearn.preprocessing as skp\n","import sklearn.utils as sku\n","import sklearn.decomposition as skd\n","import sklearn.metrics as skm\n","\n","from sklearn.manifold import TSNE\n","\n","# Module for k-fold\n","from sklearn.model_selection import KFold\n","\n","import umap.umap_ as umap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Al8QhMtvuH9n"},"outputs":[],"source":["IMAGE_HEIGHT = IMAGE_WIDTH = 128\n","\n","USE_GOOGLE_COLAB = False\n","\n","\n","CLASSES = ['a01-000u', 'c03-000a']\n","N_CLASSES_PUBLIC_DATASET = len(CLASSES)\n","N_CLASSES_PRIVATE_DATASET = 2\n","\n","FLATTEN_LAYER_NAME = 'flattened'\n","\n","DEBUG = True\n","\n","COLAB_WORKING_PATH = \"/content/drive/My Drive/Colab Notebooks/Botanist\" # Path to folder in Google Drive\n","\n","# PATHS\n","DATASET_ZIP_PATH = COLAB_WORKING_PATH # Path to \"herbier.zip\"\n","# DATASET_PATH = \"/content/data/\" # Where the unzipped data should land ?\n","DATASET_PATH = \"/content/data/\"  if USE_GOOGLE_COLAB else \"./\"\n","WORKDIR = f\"{DATASET_PATH}herbier\"\n","WORD_DATA_PATH = f\"{WORKDIR}/data_public/words/\"\n","METADATA_PATH = f\"{WORKDIR}/data_public/ascii/words.txt\"\n","\n","PRIVATE_DATASET_PATH = f\"{DATASET_PATH}/dataset/\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if USE_GOOGLE_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    !mkdir $DATASET_PATH\n","    !unzip \"$DATASET_ZIP_PATH/herbier.zip\" -d $DATASET_PATH\n","    !cd \"$DATASET_PATH/herbier\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BOKlqrvuH9o"},"outputs":[],"source":["def load_words_data(data_path, metadata_path, selected_writers = []):\n","    if selected_writers == []:\n","        raise ValueError(\"selected_writers must be a non-empty list of writer IDs\")\n","\n","    data = []\n","\n","    with open(metadata_path, 'r') as file:\n","        for line in file:\n","            if not line.startswith(\"#\"):\n","                components = line.strip().split(' ')\n","                word_id = components[0]\n","\n","                parts = word_id.split('-')\n","                writer_id = '-'.join(parts[:2])\n","\n","                if writer_id in selected_writers:\n","                    image_subfolder = parts[0]\n","                    image_filename = f\"{word_id}.png\"\n","                    image_path = os.path.join(data_path, image_subfolder, writer_id, image_filename)\n","\n","                    if os.path.exists(image_path):\n","                        try:\n","                            img = tf.io.read_file(image_path)\n","                            img = tf.image.decode_png(img)\n","                            data.append({\n","                                'image_path': image_path,\n","                                'writer_id': writer_id,\n","                                'image_array': img\n","                            })\n","                        except tf.errors.InvalidArgumentError:\n","                            print(f\"Image not found for word ID: {word_id} at {image_path}\")\n","                    else:\n","                        print(f\"Image not found for word ID: {word_id} at {image_path}\")\n","\n","    return data\n","\n","def load_new_dataset(dataset_path, num_classes=2):\n","    class_folders = os.listdir(dataset_path)\n","    selected_classes = random.sample(class_folders, num_classes)\n","    new_data = []\n","\n","    for class_name in selected_classes:\n","        class_path = os.path.join(dataset_path, class_name)\n","        for img_file in os.listdir(class_path):\n","            image_path = os.path.join(class_path, img_file)\n","            try:\n","                img = tf.io.read_file(image_path)\n","                img = tf.image.decode_png(img)\n","                new_data.append({\n","                    'image_path': image_path,\n","                    'writer_id': class_name,  # Use folder name as class name\n","                    'image_array': img\n","                })\n","            except tf.errors.InvalidArgumentError:\n","                print(f\"Image not found at {image_path}\")\n","\n","    return new_data\n","\n","public_data = load_words_data(WORD_DATA_PATH, METADATA_PATH, selected_writers=CLASSES)\n","private_data = load_new_dataset(PRIVATE_DATASET_PATH)\n","\n","combined_data = public_data + private_data\n","\n","\n","if DEBUG:\n","  print(f\"Loaded {len(combined_data)} words.\")\n","  for entry in combined_data[:5]:\n","      print(f\"  Writer ID: {entry['writer_id']}; image shape: {entry['image_array'].shape}\")\n","\n","if DEBUG:\n","  plt.figure(figsize=(10, 10))\n","  for i in range(25):\n","      plt.subplot(5, 5, i + 1)\n","      plt.xticks([])\n","      plt.yticks([])\n","      plt.grid(False)\n","      plt.imshow(combined_data[i]['image_array'], cmap=plt.cm.binary)\n","      plt.xlabel(combined_data[i]['writer_id'])\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"E006hD9Nxo67"},"source":["**Pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hulb4sWRuH9p"},"outputs":[],"source":["import cv2\n","\n","def preprocess_data(data):\n","    labels = []\n","    images = []\n","\n","    for entry in data:\n","        # Resize the image while preserving aspect ratio\n","        img = np.array(entry['image_array'])\n","        old_size = img.shape[:2]\n","\n","        ratio = float(IMAGE_HEIGHT)/old_size[0]\n","        new_size = tuple([int(x*ratio) for x in old_size])\n","\n","        img = cv2.resize(img, (new_size[1], new_size[0]))\n","\n","        # Ignore images that are too narrows\n","        if new_size[1] < IMAGE_WIDTH:\n","          continue;\n","\n","        # Crop images that are too wide\n","        if new_size[1] > IMAGE_WIDTH:\n","            start_x = (new_size[1] - IMAGE_WIDTH) // 2\n","            img = img[:, start_x:start_x + IMAGE_WIDTH]\n","            new_size = (new_size[0], IMAGE_WIDTH)\n","\n","        img = img.astype('float32') / 255.0\n","\n","        # Ensure dimensions format is correct: (sample_n, width, height, channels)\n","        img = np.expand_dims(img, axis=-1)\n","        delta_w = IMAGE_WIDTH - new_size[1]\n","        delta_h = IMAGE_HEIGHT - img.shape[0]\n","        delta_w = IMAGE_WIDTH - img.shape[1]\n","        padding = ((0, delta_h), (0, delta_w), (0, 0))\n","        img = np.pad(img, padding, 'constant')\n","\n","        images.append(img)\n","        labels.append(entry['writer_id'])\n","\n","    return np.array(images), np.array(labels)\n","\n","images, labels = preprocess_data(combined_data)\n","label_encoder = skp.LabelEncoder()\n","integer_class_labels = label_encoder.fit_transform(labels)\n","X_train, X_test, y_train, y_test = skms.train_test_split(images, integer_class_labels, test_size=0.2, random_state=42)\n","\n","\n","if DEBUG:\n","  print(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\")\n","  print(f\"X_test: {X_test.shape}; y_test: {y_test.shape}\")\n","\n","  num=5\n","  plt.figure(figsize=(10,10))\n","  for i in range(num):\n","      plt.subplot(N_CLASSES_PUBLIC_DATASET + N_CLASSES_PRIVATE_DATASET,num,i+1)\n","      plt.xticks([])\n","      plt.yticks([])\n","      plt.grid(False)\n","      plt.imshow(images[i], cmap=plt.cm.binary)\n","      plt.xlabel(labels[i])\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"1IoYwESBxxbc"},"source":["**Kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvGW_t68xynh"},"outputs":[],"source":["# Define number of splits\n","n_splits = 5\n","\n","# Create Kfold instance\n","kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"WwFl5G6ZyJw0"},"source":["**Set function to use kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYfw5twWyKTN"},"outputs":[],"source":["def train_and_evaluate(encoder_model, X_train, X_test, integer_class_labels):\n","  BATCH_SIZE = 8 # fine tuned\n","  EPOCHS = 200\n","\n","  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","  autoencoder.fit(X_train, X_train,  # input and output are the same for an autoencoder\n","                  epochs=EPOCHS,\n","                  batch_size=BATCH_SIZE,\n","                  shuffle=True,\n","                  validation_data=(X_test, X_test), \n","                  callbacks=[early_stopping])\n","\n","  ############\n","\n","  # Extract features\n","  encoded_features = encoder_model.predict(X_train)\n","\n","  # Standardize the features\n","  scaler = skp.StandardScaler()\n","  encoded_features_standardized = scaler.fit_transform(encoded_features.reshape(len(encoded_features), -1))\n","\n","\n","  ############\n","\n","  # Standardize the features\n","  # Now, use the standardized features with UMAP\n","\n","  def evaluate_model(n_neighbors, min_dist, ax):\n","      reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=32, metric='euclidean')\n","      embedding = reducer.fit_transform(np.nan_to_num(encoded_features_standardized))\n","\n","      sc = ax.scatter(embedding[:, 0], embedding[:, 1],\n","                      c=integer_class_labels, edgecolor='none', alpha=0.5,\n","                      cmap=plt.cm.get_cmap('Accent', N_CLASSES_PUBLIC_DATASET + N_CLASSES_PRIVATE_DATASET))\n","      ax.set_xlabel('UMAP component 1')\n","      ax.set_ylabel('UMAP component 2')\n","      ax.set_title(f'n_neighbors={n_neighbors}, min_dist={min_dist}')\n","\n","      if n_neighbors == n_neighbors_list[-1] and min_dist == min_dist_list[-1]:\n","          plt.colorbar(sc, ax=ax)\n","\n","  n_neighbors_list = [10, 20, 30]\n","  min_dist_list = [0.0, 0.1, 0.2]\n","\n","  fig, axes = plt.subplots(len(n_neighbors_list), len(min_dist_list), figsize=(15, 12))\n","\n","  axes = axes.flatten()\n","\n","  for idx, (n_neighbors, min_dist) in enumerate([(x, y) for x in n_neighbors_list for y in min_dist_list]):\n","      evaluate_model(n_neighbors, min_dist, axes[idx])\n","\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"e10nexn-zD5T"},"source":["**Define model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLenrqdSzEdq"},"outputs":[],"source":["# Encoder\n","input_img = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1)) # adapt this if using `channels_first` image data format\n","\n","x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n","x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","encoded = keras.layers.MaxPooling2D((2, 2), padding='same', name='encoded_layer')(x)\n","\n","# Decoder\n","x = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n","x = keras.layers.UpSampling2D((2, 2))(x)\n","x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = keras.layers.UpSampling2D((2, 2))(x)\n","x = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = keras.layers.UpSampling2D((2, 2))(x) # Additional upsampling layer\n","decoded = keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","\n","# Autoencoder model\n","autoencoder = keras.Model(input_img, decoded)\n","\n","if DEBUG:\n","    autoencoder.summary()\n","\n","autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Create a model to retrieve the encoded features\n","encoder_model = keras.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoded_layer').output)"]},{"cell_type":"markdown","metadata":{"id":"SpFlp0FDzj4Z"},"source":["**Use kfold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgHsUXjmzka7"},"outputs":[],"source":["for fold, (train_index, test_index) in enumerate(kf.split(images), 1):\n","    X_train_fold, X_test_fold = images[train_index], images[test_index]\n","    y_train_encoded_fold, y_test_encoded_fold = integer_class_labels[train_index], integer_class_labels[test_index]\n","\n","    # Train and evaluate the model for this fold\n","    train_and_evaluate(encoder_model, X_train_fold, X_test_fold, y_train_encoded_fold)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
