{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM4cyQ4hqSDq"
   },
   "source": [
    "\n",
    "# Botanist\n",
    "An academical projet to recognise and classify writings from botanists\n",
    "\n",
    "Github repo: [github.com/satche/botanist](https://github.com/satche/botanist/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66eiGtb0GyxL"
   },
   "source": [
    "## Get the data\n",
    "\n",
    "First, we'll unzip raw data of different botanists notebooks. There is a lot of images, so run it and go grab a coffee. We'll connect to your Google Drive so we can save some results and output. Make sure to change the directory according to your folder structure.\n",
    "\n",
    "*Note: the training data won't be stored in your drive as it's heavy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:26:45.044352Z",
     "start_time": "2023-12-14T11:26:44.998870Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYVUbwiGqLXh",
    "outputId": "ed664de0-59cf-4b6f-e701-b61a2ca907b8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/', force_remount=True)\n",
    "# GDRIVE_PATH = \"/content/drive/My Drive/Colab/Botanist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:26:45.049333Z",
     "start_time": "2023-12-14T11:26:45.038358Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWdTZKIkGO2Q",
    "outputId": "5e0ebd94-1f2b-4c1b-e1dd-a5e85789f041"
   },
   "outputs": [],
   "source": [
    "# !mkdir \"/data/\"\n",
    "# !unzip herbier.zip -d \"/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:26:45.053779Z",
     "start_time": "2023-12-14T11:26:45.051438Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ut5d6GesL8pI",
    "outputId": "ae788bf6-734f-461d-f36f-cc075d677157"
   },
   "outputs": [],
   "source": [
    "# data_public = os.listdir('./herbier/data_public/')\n",
    "# data_neuchatel = os.listdir('./herbier/data_neuchatel/')\n",
    "# print(data_public)\n",
    "# print(data_neuchatel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:26:46.938212Z",
     "start_time": "2023-12-14T11:26:45.053714Z"
    }
   },
   "outputs": [],
   "source": [
    "# global packages  \n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# tenserflow packages\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:26:46.946351Z",
     "start_time": "2023-12-14T11:26:46.938894Z"
    }
   },
   "outputs": [],
   "source": [
    "WORD_DATA_PATH = \"./herbier/data_public/words/\"\n",
    "METADATA_PATH = \"./herbier/data_public/ascii/words.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:26:46.947057Z",
     "start_time": "2023-12-14T11:26:46.941202Z"
    }
   },
   "outputs": [],
   "source": [
    "# J'ai tenté ceci : https://stackoverflow.com/questions/68447126/tensorflow-giving-error-invalidargumenterror-input-is-empty-when-training-or\n",
    "# Ne marche pas selon-moi car la classe d'un sample est présent dans un fichier séparé et non dans le nom du fichier\n",
    "# img_height = 64\n",
    "# img_width = 64\n",
    "# batch_size = 32\n",
    "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(WORD_DATA_PATH, labels='inferred', label_mode='int', image_size=(img_height, img_width), batch_size=batch_size)\n",
    "\n",
    "# train_ds = train_ds.map(lambda x, y: (x/255.0, y))\n",
    "\n",
    "# print(\"loaded # of images: \", len(train_ds))\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(labels[i])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:27:15.433384Z",
     "start_time": "2023-12-14T11:26:46.947199Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_words_data(data_path, metadata_path):\n",
    "    data = []\n",
    "\n",
    "    with open(metadata_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith(\"#\"):\n",
    "                # a01-000u-00-00 ok 154 408 768 27 51 AT A\n",
    "                components = line.strip().split(' ')\n",
    "                # a01-000u-00-00\n",
    "                word_id = components[0]\n",
    "                # ok\n",
    "                segmentation_result = components[1]\n",
    "                # 154\n",
    "                gray_level = int(components[2])\n",
    "                # 408 768 27 51\n",
    "                bounding_box = tuple(map(int, components[3:7]))\n",
    "                # AT\n",
    "                grammatical_tag = components[7]\n",
    "                # A\n",
    "                transcription = ' '.join(components[8:]) if len(components) > 8 else ''\n",
    "\n",
    "                parts = word_id.split('-')\n",
    "                subfolder = parts[0] + '-' + parts[1] # a01-000u\n",
    "                image_subfolder = parts[0]  # a01\n",
    "                image_filename = f\"{word_id}.png\" # a01-000u-00-00.png\n",
    "                image_path = os.path.join(data_path, image_subfolder, subfolder, image_filename)\n",
    "                \n",
    "                if os.path.exists(image_path):\n",
    "                    try: \n",
    "                        img = tf.io.read_file(image_path)\n",
    "                        img = tf.image.decode_png(img)\n",
    "                        data.append({\n",
    "                            'image_path': image_path, \n",
    "                            'word_id': word_id,\n",
    "                            'segmentation_result': segmentation_result,\n",
    "                            'gray_level': gray_level,\n",
    "                            'bounding_box': bounding_box,\n",
    "                            'grammatical_tag': grammatical_tag,\n",
    "                            'transcription': transcription,\n",
    "                            'image_array': img  # numpy array?\n",
    "                        })\n",
    "                    except tf.errors.InvalidArgumentError:\n",
    "                        print(f\"Image not found for word ID: {word_id} at {image_path}\")\n",
    "                else:\n",
    "                    print(f\"Image not found for word ID: {word_id} at {image_path}\")\n",
    "                \n",
    "                                # if os.path.exists(image_path):\n",
    "                #     try:\n",
    "                #         image = Image.open(image_path)\n",
    "                #         img_array = np.array(image)\n",
    "                #         # print(f\"Loaded image for word ID: {word_id} at {image_path};\")\n",
    "                #         data.append({\n",
    "                #             'word_id': word_id,\n",
    "                #             'segmentation_result': segmentation_result,\n",
    "                #             'gray_level': gray_level,\n",
    "                #             'bounding_box': bounding_box,\n",
    "                #             'grammatical_tag': grammatical_tag,\n",
    "                #             'transcription': transcription,\n",
    "                #             'image_array': img_array  # numpy arraz ? \n",
    "                #         })\n",
    "                #         image.close()\n",
    "                #     except Image.UnidentifiedImageError:\n",
    "                #         print(f\"Image not found for word ID: {word_id} at {image_path}\")\n",
    "                # else:\n",
    "                #     print(f\"Image not found for word ID: {word_id} at {image_path}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "words_data = load_words_data(WORD_DATA_PATH, METADATA_PATH)\n",
    "\n",
    "print(f\"Loaded {len(words_data)} words.\")\n",
    "for entry in words_data[:5]:\n",
    "    print(f\"  {entry['word_id']}: {entry['transcription']}; image shape: {entry['image_array'].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T11:31:32.273245Z",
     "start_time": "2023-12-14T11:31:23.391067Z"
    }
   },
   "outputs": [],
   "source": [
    "# def preprocess_data(words_data, img_width, img_height):\n",
    "#     X = []\n",
    "#     y = []\n",
    "\n",
    "#     for entry in words_data:\n",
    "#         # img resize\n",
    "#         resized_img = np.resize(entry['image_array'], [img_height, img_width])\n",
    "#         X.append(resized_img)\n",
    "\n",
    "#         # TODO: ground truth = transcription ? \n",
    "#         y.append(entry['transcription'])\n",
    "\n",
    "#     # normalize pixel values\n",
    "#     X = np.array(X) / 255.0\n",
    "\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def preprocess_data(words_data, img_width, img_height):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for entry in words_data:\n",
    "        # Load and resize image while maintaining aspect ratio\n",
    "        image = load_img(entry['image_path'], color_mode='grayscale', target_size=(img_height, img_width))\n",
    "        image = img_to_array(image)\n",
    "        X.append(image)\n",
    "        y.append(entry['transcription'])\n",
    "\n",
    "    # Normalize pixel values\n",
    "    X = np.array(X) / 255.0\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "img_width, img_height = 128, 128  # TODO: global variables, à ajuser\n",
    "X, y = preprocess_data(words_data, img_width, img_height)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print (f\"X_train shape: {X_train.shape}\")\n",
    "print (f\"X_test shape: {X_test.shape}\")\n",
    "print (f\"y_train shape: {y_train.shape}\")\n",
    "print (f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T11:27:21.447768Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "combined_y = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Encode all labels\n",
    "label_encoder = LabelEncoder()\n",
    "combined_y_encoded = label_encoder.fit_transform(combined_y)\n",
    "\n",
    "# Find the number of classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split them back into train and test\n",
    "split_at = len(y_train)\n",
    "y_train_encoded = combined_y_encoded[:split_at]\n",
    "y_test_encoded = combined_y_encoded[split_at:]\n",
    "\n",
    "# Convert to categorical\n",
    "y_train_categorical = tf.keras.utils.to_categorical(y_train_encoded, num_classes)\n",
    "y_test_categorical = tf.keras.utils.to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T11:27:21.448978Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T11:27:21.450117Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T11:27:21.451337Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: constants\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "history = model.fit(X_train, y_train_categorical, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test_categorical))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T11:27:21.452037Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Test')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Test')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
