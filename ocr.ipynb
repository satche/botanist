{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4cyQ4hqSDq"
      },
      "source": [
        "\n",
        "# Botanist\n",
        "An academical projet to recognise and classify writings from botanists\n",
        "\n",
        "Github repo: [github.com/satche/botanist](https://github.com/satche/botanist/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I59XyS9m1Ncv"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgWhe2namv9J"
      },
      "source": [
        "### Settings\n",
        "First, let's define some settings and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uCox8RE1SsD"
      },
      "outputs": [],
      "source": [
        "# GOOGLE COLAB\n",
        "GOOGLE_COLAB = True # Are you using Google Colab ?\n",
        "COLAB_WORKING_PATH = \"/content/drive/My Drive/Colab/Botanist\" # Path to folder in Google Drive\n",
        "\n",
        "# PATHS\n",
        "DATASET_ZIP_PATH = COLAB_WORKING_PATH # Path to \"herbier.zip\"\n",
        "DATASET_PATH = \"/content/data/\" # Where the unzipped data should land ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYVUbwiGqLXh",
        "outputId": "b228794b-29b7-4994-aaba-88c3816b0ef8"
      },
      "outputs": [],
      "source": [
        "# Mount on Google Drive\n",
        "if GOOGLE_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymRTIPCdmzIO"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G40L6mlR0zE-",
        "outputId": "eb3a1f0b-9f2d-486b-f94c-1d485cc7a8af"
      },
      "outputs": [],
      "source": [
        "# global packages\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "\"\"\"\n",
        "import pickle\n",
        "from math import exp\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import sklearn\n",
        "\"\"\"\n",
        "\n",
        "from PIL import Image\n",
        "import imghdr\n",
        "\n",
        "# OCR\n",
        "!pip install paddleocr --upgrade\n",
        "!pip install paddlepaddle\n",
        "from paddleocr import PaddleOCR,draw_ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66eiGtb0GyxL"
      },
      "source": [
        "## Get the data\n",
        "\n",
        "First, we'll unzip raw data of different botanists notebooks. There is a lot of images, so run it and go grab a coffee. We'll connect to your Google Drive so we can save some results and output. Make sure to change the directory according to your folder structure.\n",
        "\n",
        "*Note: the training data won't be stored in your drive as it's heavy*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42QKqJn24rAc",
        "outputId": "49e65d7f-431e-419c-81d2-a59211347d32"
      },
      "outputs": [],
      "source": [
        "# Create our data folder, unzip the data\n",
        "!mkdir $DATASET_PATH\n",
        "!unzip \"$DATASET_ZIP_PATH/herbier.zip\" -d $DATASET_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMFEfN8a5mmo"
      },
      "source": [
        "# OCR: handwriting detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U75q2vDb7S_0",
        "outputId": "68c35ae6-3cb1-446e-b2d6-0e3ea8f0ba13"
      },
      "outputs": [],
      "source": [
        "# Need to run only once to download and load model into memory\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "!wget -c https://github.com/PaddlePaddle/PaddleOCR/raw/release/2.7/doc/fonts/french.ttf -O \"$DATASET_PATH/herbier/fonts/french.ttf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eAIfIxm5sq2",
        "outputId": "063c510b-cc7d-4ab0-ae1b-12f66017eec1"
      },
      "outputs": [],
      "source": [
        "DETECTION_DATASET_PATH = os.path.join(DATASET_PATH, \"herbier\", \"data_neuchatel\", \"Image Chaillet pour reconnaissance Ã©criture\")\n",
        "NEW_HEIGHT = 50\n",
        "\n",
        "# Iterate over all images in the dataset\n",
        "for root, dirs, files in os.walk(DETECTION_DATASET_PATH):\n",
        "    for file in files:\n",
        "\n",
        "        img_path = os.path.join(root, file)\n",
        "        if imghdr.what(img_path) is not None:\n",
        "\n",
        "            # Detect all elements in the current image\n",
        "            result = ocr.ocr(img_path, cls=True)\n",
        "\n",
        "            for idx in range(len(result)):\n",
        "                res = result[idx]\n",
        "\n",
        "                # If res is none, ignore and continue\n",
        "                if res is None:\n",
        "                    print(f\"Could not detect anything in {img_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Each element detected has a boundary\n",
        "                for i, line in enumerate(res):\n",
        "                    boundary = line[0]\n",
        "\n",
        "                    # Convert boundaries into a format suitable for Image.crop()\n",
        "                    left = min(coord[0] for coord in boundary)\n",
        "                    upper = min(coord[1] for coord in boundary)\n",
        "                    right = max(coord[0] for coord in boundary)\n",
        "                    lower = max(coord[1] for coord in boundary)\n",
        "                    crop_boundary = (left, upper, right, lower)\n",
        "\n",
        "                    # Create folder with same name as the image to stock cropped part\n",
        "                    img_folder = img_path[:-4]\n",
        "                    if not os.path.exists(img_folder):\n",
        "                      os.makedirs(img_folder)\n",
        "\n",
        "                    # Crop the image, store in folder\n",
        "                    img = Image.open(img_path)\n",
        "                    img_crop = img.crop(crop_boundary)\n",
        "\n",
        "                    # PIL -> OpenCV\n",
        "                    img_cv = cv2.cvtColor(np.array(img_crop), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                    # White balancing\n",
        "                    wb = cv2.xphoto.createSimpleWB()\n",
        "                    img_wb = wb.balanceWhite(img_cv)\n",
        "\n",
        "                    # Grayscale\n",
        "                    img_gray = cv2.cvtColor(img_wb, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    # Thresholding\n",
        "                    _, img_thresh = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "                    # OpenCV -> PIL\n",
        "                    img_bw = Image.fromarray(img_thresh)\n",
        "\n",
        "                    # Resize by height (keep ratio)\n",
        "                    width, height = img_bw.size\n",
        "                    new_width = int((NEW_HEIGHT / height) * width)\n",
        "                    img_resized = img_bw.resize((new_width, NEW_HEIGHT))\n",
        "\n",
        "                    # Final cropped image output\n",
        "                    img_resized.save(f\"{img_folder}/crop_{i}.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
