{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4cyQ4hqSDq"
      },
      "source": [
        "\n",
        "# Botanist\n",
        "An academical projet to recognise and classify writings from botanists\n",
        "\n",
        "Github repo: [github.com/satche/botanist](https://github.com/satche/botanist/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I59XyS9m1Ncv"
      },
      "source": [
        "# Parameters\n",
        "First, let's define some settings and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uCox8RE1SsD"
      },
      "outputs": [],
      "source": [
        "# GOOGLE COLAB\n",
        "GOOGLE_COLAB = True # Are you using Google Colab ?\n",
        "COLAB_WORKING_PATH = \"/content/drive/My Drive/Colab/Botanist\" # Path to folder in Google Drive\n",
        "\n",
        "# PATHS\n",
        "DATASET_ZIP_PATH = COLAB_WORKING_PATH # Path to \"herbier.zip\"\n",
        "DATASET_PATH = \"/content/data/\" # Where the unzipped data should land ?\n",
        "WORD_DATA_PATH = \"{DATASET_PATH}/data_public/words/\"\n",
        "METADATA_PATH = \"{DATASET_PATH}/data_public/ascii/words.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66eiGtb0GyxL"
      },
      "source": [
        "## Get the data\n",
        "\n",
        "First, we'll unzip raw data of different botanists notebooks. There is a lot of images, so run it and go grab a coffee. We'll connect to your Google Drive so we can save some results and output. Make sure to change the directory according to your folder structure.\n",
        "\n",
        "*Note: the training data won't be stored in your drive as it's heavy*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G40L6mlR0zE-"
      },
      "outputs": [],
      "source": [
        "# global packages\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# tenserflow packages\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import sklearn\n",
        "\n",
        "# OCR\n",
        "!pip install paddleocr\n",
        "from paddleocr import PaddleOCR,draw_ocr\n",
        "import imghdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYVUbwiGqLXh"
      },
      "outputs": [],
      "source": [
        "# Mount on Google Drive\n",
        "if GOOGLE_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42QKqJn24rAc"
      },
      "outputs": [],
      "source": [
        "# Create our data folder, unzip the data\n",
        "!mkdir $DATASET_PATH\n",
        "!unzip \"$DATASET_ZIP_PATH/herbier.zip\" -d $DATASET_PATH\n",
        "!cd \"$DATASET_PATH/herbier\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMFEfN8a5mmo"
      },
      "source": [
        "# OCR: handwriting recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U75q2vDb7S_0"
      },
      "outputs": [],
      "source": [
        "# Need to run only once to download and load model into memory\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "!wget -c https://github.com/PaddlePaddle/PaddleOCR/raw/release/2.7/doc/fonts/french.ttf -O \"$DATASET_PATH/herbier/fonts/french.ttf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eAIfIxm5sq2"
      },
      "outputs": [],
      "source": [
        "# Writing Detection\n",
        "DETECTION_DATASET_PATH = os.path.join(DATASET_PATH, \"herbier\", \"data_neuchatel\", \"Image Chaillet pour reconnaissance Ã©criture\")\n",
        "\n",
        "# Iterate over all images in the dataset\n",
        "for root, dirs, files in os.walk(DETECTION_DATASET_PATH):\n",
        "    for file in files:\n",
        "\n",
        "        img_path = os.path.join(root, file)\n",
        "        if imghdr.what(img_path) is not None:\n",
        "\n",
        "            # Detect all elements in the current image\n",
        "            result = ocr.ocr(img_path, cls=True)\n",
        "\n",
        "            for idx in range(len(result)):\n",
        "                res = result[idx]\n",
        "\n",
        "                # If res is none, ignore and continue\n",
        "                if res is None:\n",
        "                    print(f\"Could not detect anything in {img_path}\")\n",
        "                    continue\n",
        "                \n",
        "                # Each element detected has a boundary\n",
        "                for i, line in enumerate(res):\n",
        "                    boundary = line[0]\n",
        "\n",
        "                    # Convert boundary into a format suitable for Image.crop()\n",
        "                    left = min(coord[0] for coord in boundary)\n",
        "                    upper = min(coord[1] for coord in boundary)\n",
        "                    right = max(coord[0] for coord in boundary)\n",
        "                    lower = max(coord[1] for coord in boundary)\n",
        "                    crop_boundary = (left, upper, right, lower)\n",
        "\n",
        "                    # Create folder with same name as the image to stock cropped part\n",
        "                    img_folder = img_path[:-4]\n",
        "                    if not os.path.exists(img_folder):\n",
        "                      os.makedirs(img_folder)\n",
        "\n",
        "                    # Crop the image, store in folder\n",
        "                    img = Image.open(img_path)\n",
        "                    img_crop = img.crop(crop_boundary)\n",
        "                    img_crop.save(f\"{img_folder}/crop_{i}.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
